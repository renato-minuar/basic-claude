# Claude Code Journal Configuration
# Copy this file to .env if you need custom configuration

# The journal system uses Ollama (local LLM) for AI summaries
# No API keys needed - just install Ollama and run: ollama pull llama3.2:1b

# Optional: Custom Ollama endpoint (default is http://localhost:11434)
# OLLAMA_HOST=http://localhost:11434
